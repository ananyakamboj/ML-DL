{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation of a Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Building an input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "input_layer = np.array([2,3])\n",
    "print(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Listing the weights for each layer and each node. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h1x1': array([1, 1]), 'h1x2': array([-1,  1]), 'output': array([ 2, -1])}\n"
     ]
    }
   ],
   "source": [
    "weights = {'h1x1': np.array([1,1]),\n",
    "            'h1x2': np.array([-1,1]),\n",
    "            'output': np.array([2,-1])}\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Computing the values for the hidden layer.\n",
    "- Use np.dot()\n",
    "- Or, multiply the two np.arrays. -> auto element wise multiplication. Then sum the output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "h1x1_value = np.dot(input_layer, weights['h1x1'])\n",
    "print(h1x1_value)\n",
    "\n",
    "# method 2:\n",
    "h1x1_value = np.multiply(input_layer, weights['h1x1']).sum()\n",
    "print(h1x1_value)\n",
    "\n",
    "# method 3: \n",
    "h1x1_value = (input_layer * weights['h1x1']).sum()\n",
    "print(h1x1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed values for hidden layer: 5 1\n"
     ]
    }
   ],
   "source": [
    "h1x1_value = np.dot(input_layer, weights['h1x1'])\n",
    "h1x2_value = np.dot(input_layer, weights['h1x2'])\n",
    "print(\"Computed values for hidden layer:\", h1x1_value, h1x2_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the value for the output layer.\n",
    "Since we only have one hidden layer, we'll compute the output. Otherwise, we'd use the computed values for first hidden layers to compute the values for further hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_values = np.array([h1x1_value, h1x2_value])\n",
    "output_values = np.dot(hidden_layer_values, weights['output'])\n",
    "print(output_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Forward Propagation Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagation(input_data, weights, hidden_layer_size):\n",
    "    #value computation\n",
    "    hidden_layer_values = np.zeros(hidden_layer_size)\n",
    "    \n",
    "    for i in range(hidden_layer_size):\n",
    "        hidden_layer_values[i] = np.dot(input_data, weights['hidden'][i])\n",
    "        \n",
    "    output_values = np.dot(hidden_layer_values,weights['output'])\n",
    "    return output_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = np.array([2,3])\n",
    "\n",
    "weights = {\n",
    "    'hidden':[np.array([1,1]), np.array([-1,1])],\n",
    "    'output': np.array([2,-1])\n",
    "}\n",
    "\n",
    "hidden_layer_size = 2\n",
    "\n",
    "prediction_value = forwardPropagation(input_layer,weights, hidden_layer_size)\n",
    "print(prediction_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "- Used to capture non-linearities.\n",
    "- When the relationships in the data are non-linear.\n",
    "\n",
    "- Most commonly used:\n",
    "    - Relu: Rectified Linear Activation Function\n",
    "    - Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input):\n",
    "    output = max(0, input)\n",
    "    return output\n",
    "\n",
    "# relu(3) = 3\n",
    "# relu(-3) = 0\n",
    "# tanh can be found in np.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activatedForwardPropagation(input_data, weights, hidden_layer_size):\n",
    "    #value computation\n",
    "    hidden_layer_values = np.zeros(hidden_layer_size)\n",
    "    \n",
    "    for i in range(hidden_layer_size):\n",
    "        hidden_layer_values[i] = np.dot(input_data, weights['hidden'][i])\n",
    "        hidden_layer_values[i] = relu(hidden_layer_values[i])\n",
    "        \n",
    "    output_values = np.dot(hidden_layer_values,weights['output'])\n",
    "    return relu(output_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0\n"
     ]
    }
   ],
   "source": [
    "input_layer = np.array([3,5])\n",
    "weights = {\n",
    "    'hidden': [np.array([2, 4]), np.array([ 4, -5])], \n",
    "    'output': np.array([2, 7])\n",
    "    }\n",
    "\n",
    "model_output = activatedForwardPropagation(input_layer, weights,2)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Multiple Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52.0, 63.0, 0, 148.0]\n"
     ]
    }
   ],
   "source": [
    "input_data = [np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
    "weights = {\n",
    "    'hidden': [np.array([2, 4]), np.array([ 4, -5])], \n",
    "    'output': np.array([2, 7])\n",
    "    }\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for data_point in input_data:\n",
    "    prediction = activatedForwardPropagation(data_point,weights,2)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neural network with 2 hidden layers\n",
    "\n",
    "def multiLayerNeuralNetwork(input, weights):\n",
    "    number_of_layers = len(weights['hidden'])\n",
    "    \n",
    "    for layer in range(number_of_layers):\n",
    "        hidden_layer_size = len(weights['hidden'][layer])\n",
    "        hidden_layer_values = np.zeros(hidden_layer_size)\n",
    "        \n",
    "        for i in range(hidden_layer_size):\n",
    "            hidden_layer_values[i] = np.dot(input, weights['hidden'][layer][i])\n",
    "            hidden_layer_values[i] = relu(hidden_layer_values[i])\n",
    "\n",
    "        input = hidden_layer_values\n",
    "    \n",
    "    output_values = np.dot(input,weights['output'])\n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.0\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([3,5])\n",
    "weights = {\n",
    "    'hidden': {0: [np.array([2, 4]), np.array([ 4, -5])], \n",
    "                1: [np.array([-1,  2]), np.array([1, 2])]},\n",
    "    'output': np.array([2, 7])}\n",
    "\n",
    "output = multiLayerNeuralNetwork(input_data, weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: The last layers of the model capture the most complex interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
